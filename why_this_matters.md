# Why This Matters  
### A plain-language explanation of the Privacy Witness Camera

This document explains a new kind of camera system designed for public and shared spaces.
It is written for:
- City council members and procurement committees
- Neighbors asked to serve as evidence trustees
- Journalists and the public trying to understand surveillance technology

This is not a product brochure.
It is an explanation of a **structural choice** about what cameras are allowed to become.

---

## The problem with today’s cameras

Most modern security cameras don’t just *see*.
They **remember**, **index**, and **share**.

Systems like centralized license-plate readers can:
- Track where a vehicle has been, across days or months
- Be searched retroactively (“Who drove past this house last week?”)
- Be accessed by many parties far removed from the original incident
- Be quietly repurposed later, without residents ever opting in

Even when used with good intentions, these systems create a **permanent behavioral database** of everyone who passes by.

History shows that once such a database exists, it *will* be reused, expanded, or abused.
Not because of malice—but because the capability is there.

---

## A different idea: cameras as witnesses, not databases

This system is built on a simple distinction:

> **Witnessing is not the same as watching.**

A witness:
- Observes something happen
- Makes a limited claim (“a boundary was crossed”)
- Can testify under rules
- Does not retain a perfect, searchable memory of everyone forever

A database:
- Stores everything
- Allows retroactive search
- Enables pattern mining and tracking
- Grows more powerful—and more dangerous—over time

This camera system is designed to be **a witness by construction**.

---

## What these cameras do

They detect **events**, not identities.

Examples of what they *can* say:
- “A vehicle-sized object entered this lot after hours.”
- “Someone crossed a restricted boundary.”
- “An object was removed from a defined zone.”

Each event is:
- Time-coarsened (for example, a 10-minute window, not an exact timestamp)
- Tied only to a local zone, not a GPS address
- Stored locally, under the owner’s control
- Automatically deleted after a short retention period

There is **no searchable history of people or vehicles**.

---

## What these cameras cannot do — even if misused or hacked

By design, they **cannot**:
- Store or export license plate numbers
- Identify faces or people
- Track movement across neighborhoods
- Be searched later to reconstruct someone’s past
- Be quietly upgraded to analyze old footage under new rules

This is not a promise.
It is a structural limitation.

Even the manufacturer cannot “turn it on later.”

---

## Who this protects — and from what

This design is not about abstract privacy.
It protects **real people** from very specific harms.

### The teenager near a crime scene  
A car is parked on the same street where a theft occurs.

In a centralized tracking system:
- Their license plate can be searched retroactively
- Their movements over weeks can be reconstructed
- Innocent proximity becomes suspicious history

With this system:
- There is no searchable movement history
- The camera can only attest that *an event occurred*
- There is nothing to “look up later”

Being nearby is not stored as guilt.

### The activist at a protest  
Someone attends a lawful protest or public demonstration.

In many camera systems:
- Attendance becomes part of a permanent database
- Participation can be inferred long after the event
- New laws or policies can change how old data is used

With this system:
- No identities are recorded
- No retrospective analysis is possible
- New capabilities cannot be applied to old data

Civic participation does not create a shadow record.

### The domestic violence survivor  
A person is fleeing an abusive situation and changes routines or locations.

In tracking-heavy systems:
- Movement patterns can be reconstructed
- Data breaches or misuse can expose whereabouts
- Safety depends on trusting every operator forever

With this system:
- There is no longitudinal trail to steal or subpoena
- Cameras forget by design
- Evidence exists only when deliberately sealed

Safety does not depend on secrecy — it depends on architecture.

### The innocent person who “matches a description”  
Someone happens to resemble a suspect or drive a similar vehicle.

In searchable surveillance systems:
- “Find similar” becomes a dragnet
- Error compounds over time
- Being searchable is itself a risk

With this system:
- There is no bulk search
- There is no identity index
- Suspicion cannot spread backward through history

Innocence does not require proving a negative.

### The common thread

These harms do not require bad actors.
They emerge naturally when systems:
- Remember too much
- Retain data too long
- Allow retroactive reinterpretation

This design removes those failure modes entirely.

Not by policy.
By construction.

---

## “Delete by default” does not mean “cameras don’t work”

A common concern is:
> “If you don’t keep footage, how does this help after a crime?”

The answer is **deliberate evidence**, not passive hoarding.

If a real incident occurs:
- The system can seal a short window of relevant footage locally
- That footage is encrypted and locked
- It is **not accessible by default**

---

## Break-glass by quorum: how evidence is accessed

To open sealed evidence, **multiple independent people must agree**.

For example:
- You (the property owner)
- A neighbor or community representative
- A third trustee (HOA, ombudsperson, or other agreed party)

No single person—not the owner, not the vendor, not law enforcement—can open the vault alone.

When evidence is accessed:
- The action is logged permanently
- A receipt is created showing *who* agreed and *when*
- The disclosure is limited to that specific incident

This mirrors real-world trust:
> Like three keys required to open a safe.

---

## A concrete comparison

### What a centralized plate-reader system can do
- “Show me every time this car drove through the city in the last 90 days.”
- “Find everyone who visited this address more than twice.”
- “Let’s repurpose this data for a new use later.”

### What this system can do
- “An after-hours entry occurred last night.”
- “There is sealed evidence of this specific incident.”
- “That evidence can be opened only if the agreed trustees consent.”

Even if hacked, there is **no historical movement database to steal**.

---

## Why this matters long-term

Most surveillance harm doesn’t come from day-one abuse.
It comes from:
- Gradual feature creep
- Quiet retention extensions
- New uses layered onto old data

This system blocks that path.

It makes certain futures **impossible**, not merely discouraged.

---

## The bottom line

This is a camera system that:
- Improves safety without permanent tracking
- Preserves evidence without mass surveillance
- Treats privacy as a structural boundary, not a settings menu
- Can be explained, audited, and defended in public

You don’t have to trust the operator.
You don’t have to trust the vendor.
You don’t even have to trust future lawmakers.

You only have to trust the architecture.

That is the difference between a product—and infrastructure.
